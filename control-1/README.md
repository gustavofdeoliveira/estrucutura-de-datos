# Control 1

## Bubble Sort

### Peor Caso 
- El peor caso ocurre cuando el arreglo est√° ordenado de forma decreciente.
- En este caso, el algoritmo deber√° recorrer todo el arreglo y hacer el m√°ximo n√∫mero de intercambios posibles, lo que implica que cada elemento se compara con todos los dem√°s.
- En cada iteraci√≥n del bucle externo, se realiza una comparaci√≥n para cada elemento en el bucle interno.
- Esto resulta en una complejidad temporal de `O(n¬≤)`.

### Mejor Caso

- El mejor caso ocurre cuando el arreglo ya est√° ordenado.
- El algoritmo todav√≠a ejecuta los dos bucles, pero si el arreglo est√° ordenado, no necesita hacer ning√∫n intercambio.
- Aunque recorra todo el arreglo, el algoritmo no realiza ning√∫n intercambio, resultando en una complejidad temporal de `O(n)`.

## Insertion Sort

### Peor Caso
- El peor caso ocurre cuando el arreglo est√° en orden decreciente. En este caso, para cada nuevo elemento, el bucle `while` tendr√° que recorrer toda la parte ordenada (hasta el inicio del arreglo) para encontrar el lugar correcto de inserci√≥n.
- El n√∫mero de comparaciones e intercambios en el peor caso es dado por la suma de los primeros `n-1` n√∫meros enteros.
- La complejidad temporal del peor caso es `O(n¬≤)`.

### Mejor Caso

- El mejor caso para el Insertion Sort ocurre cuando el arreglo ya est√° ordenado.
- En este caso, el bucle `while` nunca se ejecuta, ya que `array[j]` nunca ser√° mayor que `key`. El algoritmo simplemente recorre el arreglo sin hacer intercambios.
- En este escenario, el algoritmo realiza `n-1` comparaciones, una por cada iteraci√≥n del bucle externo, resultando en una complejidad temporal de `O(n)`.

## Selection Sort

### Peor Caso

- El peor caso ocurre cuando el arreglo est√° en cualquier estado (incluso desordenado), ya que el algoritmo siempre realiza el mismo n√∫mero de comparaciones.
- Para cada iteraci√≥n del arreglo (es decir, para cada posici√≥n `i`), el algoritmo necesita hacer una revisi√≥n en el resto del arreglo (desde la posici√≥n `i+1` hasta `n`).
- En el primer ciclo, se hacen `n-1` comparaciones, en el segundo ciclo se hacen `n-2` comparaciones, y as√≠ sucesivamente, hasta que solo queda 1 comparaci√≥n.

### Mejor Caso

- El mejor caso tambi√©n tiene complejidad `O(n¬≤)`. Incluso si el arreglo ya est√° ordenado, el algoritmo siempre recorre el resto del arreglo para encontrar el elemento m√°s peque√±o, lo que significa que no puede ser optimizado para detenerse antes.
- Al igual que en el peor caso, se har√°n `ùëõ(ùëõ‚àí1)/2` comparaciones, independientemente del estado inicial del arreglo.

## B√∫squeda Binaria

### Peor Caso

- En el peor caso, el valor buscado no est√° presente en el arreglo. En cada iteraci√≥n, la b√∫squeda binaria reduce a la mitad el tama√±o del intervalo de b√∫squeda. Si el arreglo tiene `n` elementos, el n√∫mero de veces que podemos dividir el arreglo a la mitad hasta que el intervalo de b√∫squeda se vac√≠e es proporcional al logaritmo de n en base 2.
- Por lo tanto, en el peor caso, la complejidad temporal de la b√∫squeda binaria es `O(log n)`, porque en cada iteraci√≥n descartamos la mitad del arreglo y el n√∫mero m√°ximo de divisiones hasta que no queden m√°s elementos es `log_2(n)`.

### Mejor Caso

- En el mejor caso, el elemento buscado est√° exactamente en el medio del arreglo en el primer intento. En este escenario, encontramos el elemento en la primera comparaci√≥n, resultando en solo una iteraci√≥n. Sin embargo, en t√©rminos de notaci√≥n asint√≥tica, aunque el mejor caso se encuentre en la primera comparaci√≥n, la complejidad sigue siendo `O(log n)`, ya que esto se considera en el crecimiento de la funci√≥n conforme aumenta el tama√±o del arreglo.

## Counting Sort

### Peor Caso
- El **peor caso** para el Counting Sort depende de dos factores:
  - `n`, el n√∫mero de elementos en el arreglo de entrada.
  - `k`, el valor m√°ximo en el arreglo (`max`).
- La complejidad temporal para cada parte del algoritmo:
  1. **Conteo de elementos**: El primer bucle recorre el arreglo de tama√±o `n`, por lo tanto, la complejidad es **O(n)**.
  2. **Acumulaci√≥n de los conteos**: El segundo bucle recorre el arreglo `count[]` de tama√±o `max + 1`, por lo que la complejidad es **O(k)**.
  3. **Construcci√≥n del arreglo ordenado**: El tercer bucle tambi√©n recorre el arreglo de tama√±o `n`, con complejidad **O(n)**.
  4. **Copia de vuelta al arreglo original**: Este bucle final tambi√©n recorre el arreglo de tama√±o `n`, con complejidad **O(n)**.

Por lo tanto, el tiempo total de ejecuci√≥n es la suma de las dos partes dominantes, resultando en una complejidad de **O(n + k)**.

### Mejor Caso
- En el **mejor caso**, el Counting Sort se comporta de la misma manera. Esto se debe a que el algoritmo no realiza optimizaciones basadas en la entrada ya ordenada, como lo hacen otros algoritmos de ordenaci√≥n.
- A√∫n necesita recorrer el arreglo de entrada para contar los elementos, acumular los conteos y construir el arreglo final. Por lo tanto, el **mejor caso** tambi√©n tiene complejidad **O(n + k)**.